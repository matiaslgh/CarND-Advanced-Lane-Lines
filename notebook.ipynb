{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect lane lines and its curvature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Camera Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the images we have to calibrate the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the the images in the directory\n",
    "CAMERA_CAL_DIR = './camera_cal/'\n",
    "calibration_img_path_list = listdir(CAMERA_CAL_DIR)\n",
    "calibration_img_path_list = [CAMERA_CAL_DIR + path for path in calibration_img_path_list]\n",
    "calibration_img_list = []\n",
    "\n",
    "# This logic is only to show all the images in rows and columns\n",
    "AMOUNT_OF_COLUMNS = 3\n",
    "amount_of_rows = len(calibration_img_path_list) // AMOUNT_OF_COLUMNS + 1\n",
    "f, axarr = plt.subplots(amount_of_rows,3)\n",
    "f.set_figheight(17)\n",
    "f.set_figwidth(17)\n",
    "\n",
    "row_counter, column_counter = 0, 0\n",
    "for img_path in calibration_img_path_list:\n",
    "    img = mpimg.imread(img_path)\n",
    "    calibration_img_list.append(img)\n",
    "    axarr[row_counter,column_counter].imshow(img)\n",
    "    column_counter += 1\n",
    "    if column_counter == AMOUNT_OF_COLUMNS:\n",
    "        column_counter = 0\n",
    "        row_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the images there are 6x9 corners, so we'll try to find them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORNERS_X = 9\n",
    "CORNERS_Y = 6\n",
    "\n",
    "objp = np.zeros((CORNERS_X * CORNERS_Y, 3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:CORNERS_X, 0:CORNERS_Y].T.reshape(-1,2)\n",
    "\n",
    "corners_img_list = []\n",
    "imgpoints = []\n",
    "objpoints = []\n",
    "for img in calibration_img_list:\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    ret, corners = cv2.findChessboardCorners(gray_img, (CORNERS_X, CORNERS_Y), None)\n",
    "    if ret == True:\n",
    "        imgpoints.append(corners)\n",
    "        objpoints.append(objp)\n",
    "        corners_img = cv2.drawChessboardCorners(img, (CORNERS_X, CORNERS_Y), corners, ret)\n",
    "        corners_img_list.append(corners_img)\n",
    "    else:\n",
    "        print('Not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 images that don't show all the corners because the picture is cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_rows = len(corners_img_list) // AMOUNT_OF_COLUMNS + 1\n",
    "f, axarr = plt.subplots(amount_of_rows,3)\n",
    "f.set_figheight(17)\n",
    "f.set_figwidth(17)\n",
    "\n",
    "row_counter, column_counter = 0, 0\n",
    "\n",
    "for img in corners_img_list:\n",
    "    axarr[row_counter,column_counter].imshow(img)\n",
    "    column_counter += 1\n",
    "    if column_counter == AMOUNT_OF_COLUMNS:\n",
    "        column_counter = 0\n",
    "        row_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have the list of corners we can proceed to calibrate the camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (corners_img_list[0].shape[1], corners_img_list[0].shape[0])\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Undistortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undistort(img):\n",
    "    return cv2.undistort(img, mtx, dist, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_original_vs_undistorted(target_img):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(target_img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(undistort(target_img))\n",
    "    ax2.set_title('Undistorted Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_original_vs_undistorted(calibration_img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_original_vs_undistorted(mpimg.imread('test_images/test4.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get binary image result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobel X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobelx_thresh(img, threshold=(0, 255), kernel=3):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobel_x = cv2.Sobel(gray_img, cv2.CV_64F,1, 0, ksize=kernel)\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    scaled_img = np.uint8(255 * abs_sobel_x / np.max(abs_sobel_x))\n",
    "\n",
    "    t_min, t_max = threshold\n",
    "    binary_output = np.zeros_like(scaled_img)\n",
    "    binary_output[(scaled_img > t_min) & (scaled_img <= t_max)] = 1\n",
    "\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = mpimg.imread('test_images/test4.jpg')\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(target_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(abs_sobelx_thresh(target_img, (40, 250), 9), cmap='gray')\n",
    "ax2.set_title('Sobel x Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by Gradient Direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dir_threshold(img, threshold=(0, np.pi/2), sobel_kernel=3):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "    sobel_x = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    absgraddir = np.arctan2(np.absolute(sobel_y), np.absolute(sobel_x))\n",
    "    \n",
    "    # Apply a threshold, and create a binary image result\n",
    "    t_min, t_max = threshold\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir > t_min) & (absgraddir <= t_max)] = 1\n",
    "\n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = mpimg.imread('test_images/test4.jpg')\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(target_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(dir_threshold(target_img, (0.8, 1.1), 9), cmap='gray')\n",
    "ax2.set_title('Gradient direction Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by Gradien Magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_threshold(img, mag_thresh=(0, 255), sobel_kernel=3):\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, sobel_kernel)\n",
    "    \n",
    "    abs_sobelxy = (sobelx ** 2 + sobely ** 2) ** 0.5\n",
    "    \n",
    "    scaled_sobel = np.uint8(255 * abs_sobelxy / np.max(abs_sobelxy))\n",
    "    \n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = mpimg.imread('test_images/test4.jpg')\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(target_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(mag_threshold(target_img, (60, 250), 9), cmap='gray')\n",
    "ax2.set_title('Gradient Magnitude Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter by Saturation Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sat_channel_threshold(img, thresh=(1, 255)):\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    sat_channel = hls_img[:,:,2]\n",
    "    \n",
    "    binary_output = np.zeros_like(sat_channel)\n",
    "    binary_output[(sat_channel >= thresh[0]) & (sat_channel <= thresh[1])] = 1\n",
    "    \n",
    "    return binary_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = mpimg.imread('test_images/test4.jpg')\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(target_img)\n",
    "ax1.set_title('Original Image', fontsize=30)\n",
    "ax2.imshow(sat_channel_threshold(target_img, (180, 255)), cmap='gray')\n",
    "ax2.set_title('Binary Saturation Channel', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the best results were got from the use of the Saturation channel and the Sobel X, I'll proceed to combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOBEL_X_THRESHOLD = (40, 250)\n",
    "SOBEL_X_KERNEL = 9\n",
    "SAT_CHANNEL_THRESHOLD = (180, 255)\n",
    "\n",
    "def get_colorful_merge(image):\n",
    "    bin_sat_img = sat_channel_threshold(image, SAT_CHANNEL_THRESHOLD)\n",
    "    sobelx_img = abs_sobelx_thresh(image, SOBEL_X_THRESHOLD, SOBEL_X_KERNEL)\n",
    "    \n",
    "    return np.dstack((bin_sat_img, sobelx_img, np.zeros_like(sobelx_img))) * 255\n",
    "\n",
    "def get_binary(image):\n",
    "    bin_sat_img = sat_channel_threshold(image, SAT_CHANNEL_THRESHOLD)\n",
    "    sobelx_img = abs_sobelx_thresh(image, SOBEL_X_THRESHOLD, SOBEL_X_KERNEL)\n",
    "\n",
    "    binary_merge = np.zeros_like(sobelx_img)\n",
    "    binary_merge[(bin_sat_img == 1) | (sobelx_img == 1)] = 1\n",
    "    \n",
    "    return binary_merge\n",
    "\n",
    "target_img = mpimg.imread('test_images/test4.jpg')\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(get_colorful_merge(target_img))\n",
    "ax1.set_title('Colorful merge', fontsize=30)\n",
    "ax2.imshow(get_binary(target_img), cmap='gray')\n",
    "ax2.set_title('Binary merge', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply birds-eye view transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to get vertices to use in transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_corners_of_trapezoid(image):\n",
    "    bottom_left = (140, image.shape[0])\n",
    "    top_left = (image.shape[1] / 2 - 67, image.shape[0] / 2 + 100)\n",
    "    top_right = (image.shape[1] / 2 + 67, image.shape[0] / 2 + 100)\n",
    "    bottom_right = (image.shape[1] - 130, image.shape[0])\n",
    "    \n",
    "    return (bottom_left, top_left, top_right, bottom_right)\n",
    "\n",
    "def get_corners_of_rectangle(corners_of_trapezoid):\n",
    "    bottom_left, top_left, top_right, bottom_right = corners_of_trapezoid\n",
    "    new_top_left = (bottom_left[0], 0)\n",
    "    new_top_right = (bottom_right[0], 0)\n",
    "    return (bottom_left, new_top_left, new_top_right, bottom_right)\n",
    "\n",
    "def to_np_array(vertices):\n",
    "    return np.array([[vertices[0], vertices[1], vertices[2], vertices[3]]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show vertices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Red trapezoid represents the source vertices\n",
    "\n",
    "Green rectangle represents the destination vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "undistorted_img = undistort(target_img)\n",
    "\n",
    "corners_of_trapezoid = get_corners_of_trapezoid(undistorted_img)\n",
    "\n",
    "# Draw trapezoid (source vertices of transformation)\n",
    "cv2.polylines(undistorted_img, to_np_array(corners_of_trapezoid), True, (255, 0 , 0), thickness=8)\n",
    "\n",
    "# Draw rectangle (destination vertices of transformation)\n",
    "corners_of_rectangle = get_corners_of_rectangle(corners_of_trapezoid)\n",
    "cv2.polylines(undistorted_img, to_np_array(corners_of_rectangle), True, (0, 255 , 0), thickness=8)\n",
    "\n",
    "plt.imshow(undistorted_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create transformation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = np.float32([corners_of_trapezoid])\n",
    "dst = np.float32([corners_of_rectangle])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(src, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define bird_eye function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bird_eye(image, is_distorted=False, show_rectangle=False):\n",
    "    if is_distorted:\n",
    "        undistorted_img = undistort(image)\n",
    "    else:\n",
    "        undistorted_img = image\n",
    "\n",
    "    img_size = (undistorted_img.shape[1], undistorted_img.shape[0])\n",
    "    warped_img = cv2.warpPerspective(undistorted_img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    if (show_rectangle):\n",
    "        cv2.polylines(warped_img, to_np_array(((185, 710), (185, 0), (1100, 0), (1100, 710))), True, (0, 255 , 0), thickness=8)\n",
    "        \n",
    "    return warped_img  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show some results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "plt.imshow(bird_eye(target_img, True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = mpimg.imread('test_images/test3.jpg')\n",
    "plt.imshow(bird_eye(target_img, True, True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Detect lane lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw histogram with amount of pixels in axis Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_img = mpimg.imread('test_images/straight_lines1.jpg')\n",
    "undistorted_img = undistort(target_img)\n",
    "binary_img = get_binary(undistorted_img)\n",
    "binary_warped_img = bird_eye(binary_img)\n",
    "\n",
    "plt.imshow(binary_warped_img, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(binary_img):\n",
    "    lower_half = binary_img[:binary_img.shape[0] // 2]\n",
    "    return np.sum(lower_half, axis=0)\n",
    "\n",
    "plt.plot(get_histogram(binary_warped_img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find lane lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use histogram to find the mean X value where are most of the pixels for both left and right lane lines\n",
    "- With those initial positions, draw small windows to detect the lane pixels in those windows\n",
    "- Recenter every window if the previous one had enough amount of pixels\n",
    "- Return the indices of the pixels that are lane lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_WINDOWS = 10\n",
    "WINDOW_WIDTH = 100\n",
    "MIN_PIX = 50\n",
    "\n",
    "def draw_window(img, bottom_left_point, top_right_point):\n",
    "    cv2.rectangle(img, bottom_left_point, top_right_point, (0,255,0), 2)\n",
    "    \n",
    "def build_get_nonzero_pixels_within_window(window_y_low, window_y_high, nonzerox, nonzeroy, output_img=None):\n",
    "    def get_nonzero_pixels_within_window(x_current, window_width=WINDOW_WIDTH):\n",
    "        # Get window's boundaries\n",
    "        window_x_low = x_current - window_width\n",
    "        window_x_high = x_current + window_width\n",
    "\n",
    "        if type(output_img) is np.ndarray:\n",
    "            bottom_left_point = (window_x_low, window_y_low)\n",
    "            top_right_point = (window_x_high, window_y_high)\n",
    "            draw_window(output_img, bottom_left_point, top_right_point)\n",
    "\n",
    "        return (\n",
    "            (nonzeroy >= window_y_low) &\n",
    "            (nonzeroy < window_y_high) & \n",
    "            (nonzerox >= window_x_low) &\n",
    "            (nonzerox < window_x_high)\n",
    "        ).nonzero()[0]\n",
    "\n",
    "        return nonzero_pixels_within_window\n",
    "    \n",
    "    return get_nonzero_pixels_within_window\n",
    "\n",
    "def recenter_if_enough_pixels_found(indices, nonzerox, current):\n",
    "    if len(indices) > MIN_PIX:\n",
    "        return np.int(np.mean(nonzerox[indices]))\n",
    "    else:\n",
    "        return current\n",
    "    \n",
    "def get_best_x_base(initial_x, image_height, nonzerox, nonzeroy):\n",
    "    '''\n",
    "    Sometimes the initial x (which we get from the peak of the histogram) don't have enough pixels\n",
    "    For those cases we can double the window's width to recenter the first x\n",
    "    '''\n",
    "    window_height = np.int(image_height // N_WINDOWS)\n",
    "    win_y_low = image_height - window_height\n",
    "    get_nonzero_pixels_within_window = build_get_nonzero_pixels_within_window(\n",
    "        win_y_low,\n",
    "        image_height,\n",
    "        nonzerox,\n",
    "        nonzeroy\n",
    "    )\n",
    "    indices = get_nonzero_pixels_within_window(initial_x)\n",
    "    if len(indices) > MIN_PIX:\n",
    "        return initial_x\n",
    "    else:\n",
    "        indices = get_nonzero_pixels_within_window(initial_x, WINDOW_WIDTH * 2)\n",
    "        if len(indices) == 0:\n",
    "            return initial_x\n",
    "        return np.int(np.mean(nonzerox[indices]))\n",
    "    \n",
    "def find_lane_pixels(binary_warped_img):\n",
    "    histogram = get_histogram(binary_warped_img)\n",
    "\n",
    "    # Windows height based on N_WINDOWS\n",
    "    img_height = binary_warped_img.shape[0]\n",
    "    window_height = np.int(img_height // N_WINDOWS)\n",
    "\n",
    "    # Identify the x and y positions of all the activated pixels in the image\n",
    "    nonzero = binary_warped_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Get start points\n",
    "    mid_x = binary_warped_img.shape[1] // 2\n",
    "    leftx_base = np.argmax(histogram[:mid_x])\n",
    "    rightx_base = np.argmax(histogram[mid_x:]) + mid_x\n",
    "\n",
    "    leftx_current = get_best_x_base(leftx_base, img_height, nonzerox, nonzeroy)\n",
    "    rightx_current = get_best_x_base(rightx_base, img_height, nonzerox, nonzeroy)\n",
    "    left_lane_indices, right_lane_indices = [], []\n",
    "\n",
    "    output_img = np.dstack((binary_warped_img, binary_warped_img, binary_warped_img)) * 255\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(N_WINDOWS):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped_img.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = binary_warped_img.shape[0] - window * window_height\n",
    "\n",
    "        # Build function already configured to get nonzero pixels within the window\n",
    "        get_nonzero_pixels_within_window = build_get_nonzero_pixels_within_window(\n",
    "            win_y_low,\n",
    "            win_y_high,\n",
    "            nonzerox,\n",
    "            nonzeroy,\n",
    "            output_img\n",
    "        )\n",
    "\n",
    "        good_left_indices = get_nonzero_pixels_within_window(leftx_current)\n",
    "        good_right_indices = get_nonzero_pixels_within_window(rightx_current)\n",
    "\n",
    "        # Append these indices to the lists\n",
    "        left_lane_indices.append(good_left_indices)\n",
    "        right_lane_indices.append(good_right_indices)\n",
    "\n",
    "        # Only recenter if we found enough pixels (we don't want to recenter if the window does not include enough pixels)\n",
    "        leftx_current = recenter_if_enough_pixels_found(good_left_indices, nonzerox, leftx_current)\n",
    "        rightx_current = recenter_if_enough_pixels_found(good_right_indices, nonzerox, rightx_current)\n",
    "        \n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_indices = np.concatenate(left_lane_indices)\n",
    "        right_lane_indices = np.concatenate(right_lane_indices)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_indices]\n",
    "    lefty = nonzeroy[left_lane_indices] \n",
    "    rightx = nonzerox[right_lane_indices]\n",
    "    righty = nonzeroy[right_lane_indices]\n",
    "\n",
    "    return leftx, lefty, rightx, righty, output_img\n",
    "\n",
    "\n",
    "leftx, lefty, rightx, righty, output_img = find_lane_pixels(binary_warped_img)\n",
    "plt.imshow(output_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use lane pixels to get a polynomial function that fits with those values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know that the lines should be parallel, we can get the average of the coefficients to smooth any errors and keep a final result with parallel lines. We keep the original third coefficient because it's the one that indicates the offset, which we don't want to change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial(binary_warped_img):\n",
    "    # Find the lane pixels first\n",
    "    leftx, lefty, rightx, righty, output_img = find_lane_pixels(binary_warped_img)\n",
    "\n",
    "    # Fit a second order polynomial for both lines\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Since the lines should be parallel we'll calculate the average between both results\n",
    "    avg_a_coefficient = (left_fit[0] + right_fit[0]) / 2\n",
    "    avg_b_coefficient = (left_fit[1] + right_fit[1]) / 2\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, binary_warped_img.shape[0]-1, binary_warped_img.shape[0] )\n",
    "    try:\n",
    "        left_fitx = avg_a_coefficient*ploty**2 + avg_b_coefficient*ploty + left_fit[2]\n",
    "        right_fitx = avg_a_coefficient*ploty**2 + avg_b_coefficient*ploty + right_fit[2]\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "        left_fitx = 1*ploty**2 + 1*ploty\n",
    "        right_fitx = 1*ploty**2 + 1*ploty\n",
    "\n",
    "    ## Visualization ##\n",
    "    # Colors in the left and right lane regions\n",
    "    output_img[lefty, leftx] = [255, 0, 0]\n",
    "    output_img[righty, rightx] = [0, 0, 255]\n",
    "\n",
    "    # Plots the left and right polynomials on the lane lines\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "\n",
    "    return output_img\n",
    "\n",
    "plt.imshow(fit_polynomial(binary_warped_img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
